{"cells":[{"cell_type":"markdown","source":["#Numba"],"metadata":{"id":"3TsGU1EpgORN"}},{"cell_type":"markdown","source":["1. https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda.ipynb#scrollTo=Ctr6aM3cmkdx\n","\n","2. https://stackoverflow.com/questions/48811248/how-to-use-numba-in-colaboratory"],"metadata":{"id":"Yc-AuJkZkAu1"}},{"cell_type":"code","source":["!find / -iname 'libdevice'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4e8Z0qM8fB1M","executionInfo":{"status":"ok","timestamp":1666928633801,"user_tz":240,"elapsed":10868,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"72d8b4db-4759-4595-9a4f-87d690e5ba35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["find: ‘/proc/45/task/45/net’: Invalid argument\n","find: ‘/proc/45/net’: Invalid argument\n","/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\n","/usr/local/cuda-11.2/nvvm/libdevice\n","/usr/local/cuda-11.2/nvvm-prev/libdevice\n"]}]},{"cell_type":"code","source":["!find / -iname 'libnvvm.so'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOzI8jmDgJ-M","executionInfo":{"status":"ok","timestamp":1666928635932,"user_tz":240,"elapsed":2136,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"37be9482-1447-468a-d270-84e577528a02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["find: ‘/proc/45/task/45/net’: Invalid argument\n","find: ‘/proc/45/net’: Invalid argument\n","/usr/local/cuda-11.2/nvvm/lib64/libnvvm.so\n","/usr/local/cuda-11.2/nvvm-prev/lib64/libnvvm.so\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-11.2/nvvm/libdevice\"\n","os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-11.2/nvvm-prev/lib64/libnvvm.so\""],"metadata":{"id":"a-Jyus7jf-mM","executionInfo":{"status":"ok","timestamp":1667446653008,"user_tz":240,"elapsed":391,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from numba import jit"],"metadata":{"id":"R_FSUJU7hAOn","executionInfo":{"status":"ok","timestamp":1667446654795,"user_tz":240,"elapsed":1134,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YdFl3x2SBBFf"},"source":["#Package Section"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"1feGDRiBv-2-","executionInfo":{"status":"ok","timestamp":1667446107653,"user_tz":240,"elapsed":4254,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["import sys\n","import numpy as np\n","import copy\n","from numpy import linalg as LA\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics.cluster import adjusted_rand_score\n","from sklearn.cluster import KMeans\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn import metrics\n","import time\n","# for sparse matrix\n","from scipy import sparse\n","#early stop\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ModelCheckpoint\n"]},{"cell_type":"markdown","source":["#Classes and functions(original)"],"metadata":{"id":"rdtkqKg_nhmj"}},{"cell_type":"code","source":["# invalide devide resutls will be nan\n","np.seterr(divide='ignore', invalid='ignore')\n","\n","############------------graph_encoder_embed_start----------------###############\n","class GraphEncoderEmbed:\n","  def run(self, X, Y, n, **kwargs):\n","    defaultKwargs = {'EdgeList': False, 'DiagA': True, 'Laplacian': False, 'Correlation': True}\n","    kwargs = { **defaultKwargs, **kwargs}\n","\n","    if kwargs['EdgeList']:\n","      size_flag = self.edge_list_size\n","      X = self.Edge_to_Sparse(X, n, size_flag)\n","    \n","    emb_strat = time.time()\n","\n","    if kwargs['DiagA']:\n","      X = self.Diagonal(X, n)\n","\n","    if kwargs['Laplacian']:\n","      X = self.Laplacian(X, n)\n","    \n","    Z, W = self.Basic(X, Y, n)\n","\n","    if kwargs['Correlation']:\n","      Z = self.Correlation(Z)\n","    \n","    emb_end = time.time()\n","    emb_time = emb_end - emb_strat\n","    \n","    return Z, W, emb_time\n","\n","  def Basic(self, X, Y, n):\n","    \"\"\"\n","      graph embedding basic function\n","      input X is sparse csr matrix of adjacency matrix\n","      -- if there is a connection between node i and node j:\n","      ---- X(i,j) = 1, no edge weight\n","      ---- X(i,j) = edge weight.\n","      -- if there is no connection between node i and node j:\n","      ---- X(i,j) = 0, \n","      ---- note there is no storage for this in sparse matrix. \n","      ---- No storage means 0 in sparse matrix.\n","      input Y is numpy array with size (n,1):\n","      -- value -1 indicate no lable\n","      -- value >=0 indicate real label\n","      input train_idx: a list of indices of input X for training set \n","    \"\"\"\n","    # assign k to the max along the first column\n","    # Note for python, label Y starts from 0. Python index starts from 0. thus size k should be max + 1\n","    k = Y[:,0].max() + 1\n","    \n","    #nk: 1*n array, contains the number of observations in each class\n","    nk = np.zeros((1,k))\n","    for i in range(k):\n","      nk[0,i] = np.count_nonzero(Y[:,0]==i)\n","    \n","    #W: sparse matrix for encoder matrix. W[i,k] = {1/nk if Yi==k, otherwise 0}\n","    W = sparse.dok_matrix((n, k), dtype=np.float32)\n","\n","    for i in range(n):\n","      k_i = Y[i,0]\n","      if k_i >=0:\n","        # W[i,k_i] = 1/nk[0,k_i] ## GEE paper\n","        W[i,k_i] = nk[0,k_i]/n ## use as an example to show if people want to use nk/n instead of 1/nk\n","    \n","    W = sparse.csr_matrix(W)\n","    Z = X.dot(W)\n","\n","    return Z, W\n","\n","  def Diagonal(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of X matrix with 1s on the diagonal\n","    \"\"\"\n","    I = sparse.identity(n)\n","    X = X + I\n","    return X\n","\n","  def Laplacian(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of Laplacian normalization of X matrix\n","    \"\"\"\n","    X_sparse = sparse.csr_matrix(X)\n","    # get an array of degrees\n","    dig = X_sparse.sum(axis=0).A1\n","    # diagonal sparse matrix of D\n","    D = sparse.diags(dig,0)\n","    _D = D.power(-0.5)\n","    # D^-0.5 x A x D^-0.5\n","    L = _D.dot(X_sparse.dot(_D)) \n","\n","    # _L = _D.dot(X_sparse.dot(_D))    \n","    # # L = I - D^-0.5 x A x D^-0.5\n","    # I = sparse.identity(n)\n","    # L = I - _L   \n","\n","    return L\n","  \n","  def Correlation(self, Z):\n","    \"\"\"\n","      input Z is sparse csr matrix of embedding matrix from the basic function\n","      return normalized Z sparse matrix\n","      Calculation:\n","      Calculate each row's 2-norm (Euclidean distance). \n","      e.g.row_x: [ele_i,ele_j,ele_k]. norm2 = sqr(sum(ele_i^2+ele_i^2+ele_i^2))\n","      then divide each element by their row norm\n","      e.g. [ele_i/norm2,ele_j/norm2,ele_k/norm2] \n","    \"\"\"\n","    # 2-norm\n","    row_norm = sparse.linalg.norm(Z, axis = 1)\n","\n","    # row division to get the normalized Z\n","    diag = np.nan_to_num(1/row_norm)\n","    N = sparse.diags(diag,0)\n","    Z = N.dot(Z)\n","\n","    return Z\n","  \n","  def edge_list_size(self, X):\n","    \"\"\"\n","      set default edge list size as S3.\n","      If find X only has 2 columns, \n","      return a flag \"S2\" indicating this is S2 edge list\n","    \"\"\"\n","    if X.shape[1] == 2:\n","      return \"S2\"\n","    else:\n","      return \"S3\"\n","    \n","  def Edge_to_Sparse(self, X, n, size_flag):\n","    \"\"\"\n","      input X is an edge list.\n","      Note for X, the edge list: \n","      it is assumed there is no duplication of one connection\n","      e.g. connection between node i and node j, \n","      there is only one row for this connection. \n","      either (node_i, node_j, edge_w), or(node_j, node_i, edge_w)\n","      Only one of them. \n","      If there are duplication in your edge list, please remove them before run.\n","\n","      For S2 edge list (e.g. node_i, node_j per row), add one to all connections\n","      return a sparse csr matrix of S3 edge list\n","    \"\"\"   \n","    #Build an empty sparse matrix. \n","    X_new = sparse.dok_matrix((n, n), dtype=np.float32)\n","\n","    for row in X:\n","      if size_flag == \"S2\":\n","        [node_i, node_j] = row\n","        X_new[node_i, node_j] = 1\n","        X_new[node_j, node_i] = 1\n","      else:\n","        [node_i, node_j, weight] = row\n","        X_new[node_i, node_j] = weight\n","        X_new[node_j, node_i] = weight\n","    \n","    X_new = sparse.csr_matrix(X_new)\n","\n","    return X_new\n","\n","\n","############------------graph_encoder_embed_end------------------###############\n","############------------Sparse_supervised_learning_start---------###############\n","\n","# https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/22567\n","# https://github.com/tkipf/pygcn/blob/1600b5b748b3976413d1e307540ccc62605b4d6d/pygcn/utils.py#L73\n","\n","def batch_generator(X, y, k, batch_size, shuffle):\n","    number_of_batches = int(X.shape[0]/batch_size)\n","    counter = 0\n","    sample_index = np.arange(X.shape[0])\n","    if shuffle:\n","        np.random.shuffle(sample_index)\n","    while True:\n","        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n","        X_batch = X[batch_index,:].toarray()\n","        y_batch = to_categorical(y[batch_index], num_classes=k)\n","        counter += 1\n","        yield X_batch, y_batch\n","        if (counter == number_of_batches):\n","            if shuffle:\n","                np.random.shuffle(sample_index)\n","            counter = 0\n","\n","class Hyperperameters:\n","  \"\"\"\n","    define perameters for GNN.\n","    default values are for GNN learning -- \"Leaner\" ==2:\n","      embedding via partial label, then learn unknown label via two-layer NN\n","\n","  \"\"\"\n","  def __init__(self):\n","    # there is no scaled conjugate gradiant in keras optimiser, use defualt instead\n","    # use whatever default\n","    self.learning_rate = 0.01  # Initial learning rate.\n","    self.epochs = 100 #Number of epochs to train.\n","    self.hidden = 20 #Number of units in hidden layer \n","    self.val_split = 0.1 #Split 10% of training data for validation\n","    self.loss = 'categorical_crossentropy' # loss function\n","\n","class GNN:\n","  def __init__(self, DataSets):\n","    GNN.DataSets = DataSets\n","    GNN.hyperM = Hyperperameters()\n","    GNN.model = self.GNN_model()  #model summary: GNN.model.summary()\n","      \n"," \n","  def GNN_model(self):\n","    \"\"\"\n","      build GNN model\n","    \"\"\"\n","    hyperM = self.hyperM\n","    DataSets = self.DataSets\n","\n","    z_train = DataSets.z_train\n","    k = DataSets.d\n","\n","    feature_num = z_train.shape[1]\n","    \n","    model = keras.Sequential([\n","    keras.layers.Flatten(input_shape = (feature_num,)),  # input layer \n","    keras.layers.Dense(hyperM.hidden, activation='relu'),  # hidden layer -- no tansig activation function in Keras, use relu instead\n","    keras.layers.Dense(k, activation='softmax') # output layer, matlab used softmax for patternnet default ??? max(opts.neuron,K)? opts \n","    ])\n","\n","    optimizer = keras.optimizers.Adam(learning_rate = hyperM.learning_rate)\n","\n","    model.compile(optimizer='adam',\n","                  loss=hyperM.loss,\n","                  metrics=['accuracy'])\n","\n","    return model\n","    \n","  def GNN_run(self, flag):\n","    \"\"\"\n","      Train and test directly.\n","      Do not learn from the unknown labels.\n","    \"\"\"\n","    gnn = copy.deepcopy(self)\n","    hyperM = gnn.hyperM\n","    DataSets = self.DataSets\n","    k = DataSets.d\n","    z_train = DataSets.z_train\n","    y_train = DataSets.y_train\n","    y_test = DataSets.y_test\n","    z_test = DataSets.z_test\n","    model = gnn.model    \n","\n","\n","    if flag == \"direct\":\n","      y_train_one_hot = to_categorical(y_train, num_classes=k)\n","      train_strat = time.time() \n","      history = model.fit(z_train.toarray(), y_train_one_hot, \n","        validation_split=hyperM.val_split,\n","        epochs=hyperM.epochs, \n","        shuffle=True,\n","        verbose=0)\n","    else:\n","      early_stopping_callback = EarlyStopping(monitor='loss', patience=5, verbose=0)\n","      checkpoint_callback = ModelCheckpoint('GNN.h5', monitor='loss', save_best_only=True, mode='min', verbose=0)\n","      \n","      train_strat = time.time()\n","      history = model.fit(batch_generator(z_train, y_train, k, 32, True),\n","                      epochs=hyperM.epochs,\n","                      steps_per_epoch=z_train.shape[0],\n","                      callbacks=[early_stopping_callback, checkpoint_callback],\n","                      verbose=0)\n","    train_end = time.time()\n","    train_time = train_end - train_strat \n","\n","    y_test_one_hot = to_categorical(y_test, num_classes=k) \n","    # set verbose to 0 to silent the output\n","    test_loss, test_acc = gnn.model.evaluate(z_test.toarray(),  y_test_one_hot, verbose=0) \n","    return test_acc, train_time\n","############------------Sparse_supervised_learning_end---------###############\n"],"metadata":{"id":"d60qfGLDnY2q","executionInfo":{"status":"ok","timestamp":1667446627211,"user_tz":240,"elapsed":302,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4N9L480srX8a"},"source":["#Classes and functions with Numba Decorator"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QpkZjKLAskam","executionInfo":{"status":"ok","timestamp":1667442049424,"user_tz":240,"elapsed":269,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["# invalide devide resutls will be nan\n","np.seterr(divide='ignore', invalid='ignore')\n","\n","############------------graph_encoder_embed_start----------------###############\n","class GraphEncoderEmbed:\n","  def run(self, X, Y, n, **kwargs):\n","    defaultKwargs = {'EdgeList': False, 'DiagA': True, 'Laplacian': False, 'Correlation': True}\n","    kwargs = { **defaultKwargs, **kwargs}\n","\n","    if kwargs['EdgeList']:\n","      size_flag = self.edge_list_size\n","      X = self.Edge_to_Sparse(X, n, size_flag)\n","    \n","    emb_strat = time.time()\n","\n","    if kwargs['DiagA']:\n","      X = self.Diagonal(X, n)\n","\n","    if kwargs['Laplacian']:\n","      X = self.Laplacian(X, n)\n","    \n","    Z, W = self.Basic(X, Y, n)\n","\n","    if kwargs['Correlation']:\n","      Z = self.Correlation(Z)\n","    \n","    emb_end = time.time()\n","    emb_time = emb_end - emb_strat\n","    \n","    return Z, W, emb_time\n","\n","  def Basic(self, X, Y, n):\n","    \"\"\"\n","      graph embedding basic function\n","      input X is sparse csr matrix of adjacency matrix\n","      -- if there is a connection between node i and node j:\n","      ---- X(i,j) = 1, no edge weight\n","      ---- X(i,j) = edge weight.\n","      -- if there is no connection between node i and node j:\n","      ---- X(i,j) = 0, \n","      ---- note there is no storage for this in sparse matrix. \n","      ---- No storage means 0 in sparse matrix.\n","      input Y is numpy array with size (n,1):\n","      -- value -1 indicate no lable\n","      -- value >=0 indicate real label\n","      input train_idx: a list of indices of input X for training set \n","    \"\"\"\n","    # assign k to the max along the first column\n","    # Note for python, label Y starts from 0. Python index starts from 0. thus size k should be max + 1\n","    k = Y[:,0].max() + 1\n","    \n","    #nk: 1*n array, contains the number of observations in each class\n","    nk = np.zeros((1,k))\n","    for i in range(k):\n","      nk[0,i] = np.count_nonzero(Y[:,0]==i)\n","    \n","    #W: sparse matrix for encoder matrix. W[i,k] = {1/nk if Yi==k, otherwise 0}\n","    W = sparse.dok_matrix((n, k), dtype=np.float32)\n","\n","    for i in range(n):\n","      k_i = Y[i,0]\n","      if k_i >=0:\n","        W[i,k_i] = 1/nk[0,k_i] ## GEE paper\n","        # W[i,k_i] = nk[0,k_i]/n ## use as an example to show if people want to use nk/n instead of 1/nk\n","    \n","    W = sparse.csr_matrix(W)\n","    Z = X.dot(W)\n","\n","    return Z, W\n","\n","  def Diagonal(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of X matrix with 1s on the diagonal\n","    \"\"\"\n","    I = sparse.identity(n)\n","    X = X + I\n","    return X\n","\n","  def Laplacian(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of Laplacian normalization of X matrix\n","    \"\"\"\n","    X_sparse = sparse.csr_matrix(X)\n","    # get an array of degrees\n","    dig = X_sparse.sum(axis=0).A1\n","    # diagonal sparse matrix of D\n","    D = sparse.diags(dig,0)\n","    _D = D.power(-0.5)\n","    # D^-0.5 x A x D^-0.5\n","    L = _D.dot(X_sparse.dot(_D)) \n","\n","    # _L = _D.dot(X_sparse.dot(_D))    \n","    # # L = I - D^-0.5 x A x D^-0.5\n","    # I = sparse.identity(n)\n","    # L = I - _L   \n","\n","    return L\n","  \n","  def Correlation(self, Z):\n","    \"\"\"\n","      input Z is sparse csr matrix of embedding matrix from the basic function\n","      return normalized Z sparse matrix\n","      Calculation:\n","      Calculate each row's 2-norm (Euclidean distance). \n","      e.g.row_x: [ele_i,ele_j,ele_k]. norm2 = sqr(sum(ele_i^2+ele_i^2+ele_i^2))\n","      then divide each element by their row norm\n","      e.g. [ele_i/norm2,ele_j/norm2,ele_k/norm2] \n","    \"\"\"\n","    # 2-norm\n","    row_norm = sparse.linalg.norm(Z, axis = 1)\n","\n","    # row division to get the normalized Z\n","    diag = np.nan_to_num(1/row_norm)\n","    N = sparse.diags(diag,0)\n","    Z = N.dot(Z)\n","\n","    return Z\n","  \n","  @jit(nopython = True)\n","  def edge_list_size(self, X):\n","    \"\"\"\n","      set default edge list size as S3.\n","      If find X only has 2 columns, \n","      return a flag \"S2\" indicating this is S2 edge list\n","    \"\"\"\n","    if X.shape[1] == 2:\n","      return \"S2\"\n","    else:\n","      return \"S3\"\n","    \n","  def Edge_to_Sparse(self, X, n, size_flag):\n","    \"\"\"\n","      input X is an edge list.\n","      Note for X, the edge list: \n","      it is assumed there is no duplication of one connection\n","      e.g. connection between node i and node j, \n","      there is only one row for this connection. \n","      either (node_i, node_j, edge_w), or(node_j, node_i, edge_w)\n","      Only one of them. \n","      If there are duplication in your edge list, please remove them before run.\n","\n","      For S2 edge list (e.g. node_i, node_j per row), add one to all connections\n","      return a sparse csr matrix of S3 edge list\n","    \"\"\"   \n","    #Build an empty sparse matrix. \n","    X_new = sparse.dok_matrix((n, n), dtype=np.float32)\n","\n","    for row in X:\n","      if size_flag == \"S2\":\n","        [node_i, node_j] = row\n","        X_new[node_i, node_j] = 1\n","        X_new[node_j, node_i] = 1\n","      else:\n","        [node_i, node_j, weight] = row\n","        X_new[node_i, node_j] = weight\n","        X_new[node_j, node_i] = weight\n","    \n","    X_new = sparse.csr_matrix(X_new)\n","\n","    return X_new\n","\n","############------------graph_encoder_embed_end------------------###############\n","############------------Sparse_supervised_learning_start---------###############\n","\n","# https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/22567\n","# https://github.com/tkipf/pygcn/blob/1600b5b748b3976413d1e307540ccc62605b4d6d/pygcn/utils.py#L73\n","\n","def batch_generator(X, y, k, batch_size, shuffle):\n","    number_of_batches = int(X.shape[0]/batch_size)\n","    counter = 0\n","    sample_index = np.arange(X.shape[0])\n","    if shuffle:\n","        np.random.shuffle(sample_index)\n","    while True:\n","        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n","        X_batch = X[batch_index,:].toarray()\n","        y_batch = to_categorical(y[batch_index], num_classes=k)\n","        counter += 1\n","        yield X_batch, y_batch\n","        if (counter == number_of_batches):\n","            if shuffle:\n","                np.random.shuffle(sample_index)\n","            counter = 0\n","\n","class Hyperperameters:\n","  \"\"\"\n","    define perameters for GNN.\n","    default values are for GNN learning -- \"Leaner\" ==2:\n","      embedding via partial label, then learn unknown label via two-layer NN\n","\n","  \"\"\"\n","  def __init__(self):\n","    # there is no scaled conjugate gradiant in keras optimiser, use defualt instead\n","    # use whatever default\n","    self.learning_rate = 0.01  # Initial learning rate.\n","    self.epochs = 100 #Number of epochs to train.\n","    self.hidden = 20 #Number of units in hidden layer \n","    self.val_split = 0.1 #Split 10% of training data for validation\n","    self.loss = 'categorical_crossentropy' # loss function\n","\n","class GNN:\n","  def __init__(self, DataSets):\n","    GNN.DataSets = DataSets\n","    GNN.hyperM = Hyperperameters()\n","    GNN.model = self.GNN_model()  #model summary: GNN.model.summary()\n","      \n"," \n","  def GNN_model(self):\n","    \"\"\"\n","      build GNN model\n","    \"\"\"\n","    hyperM = self.hyperM\n","    DataSets = self.DataSets\n","\n","    z_train = DataSets.z_train\n","    k = DataSets.d\n","\n","    feature_num = z_train.shape[1]\n","    \n","    model = keras.Sequential([\n","    keras.layers.Flatten(input_shape = (feature_num,)),  # input layer \n","    keras.layers.Dense(hyperM.hidden, activation='relu'),  # hidden layer -- no tansig activation function in Keras, use relu instead\n","    keras.layers.Dense(k, activation='softmax') # output layer, matlab used softmax for patternnet default ??? max(opts.neuron,K)? opts \n","    ])\n","\n","    optimizer = keras.optimizers.Adam(learning_rate = hyperM.learning_rate)\n","\n","    model.compile(optimizer='adam',\n","                  loss=hyperM.loss,\n","                  metrics=['accuracy'])\n","\n","    return model\n","    \n","  def GNN_run(self, flag):\n","    \"\"\"\n","      Train and test directly.\n","      Do not learn from the unknown labels.\n","    \"\"\"\n","    gnn = copy.deepcopy(self)\n","    hyperM = gnn.hyperM\n","    DataSets = self.DataSets\n","    k = DataSets.d\n","    z_train = DataSets.z_train\n","    y_train = DataSets.y_train\n","    y_test = DataSets.y_test\n","    z_test = DataSets.z_test\n","    model = gnn.model    \n","\n","\n","    if flag == \"direct\":\n","      y_train_one_hot = to_categorical(y_train, num_classes=k)\n","      train_strat = time.time() \n","      history = model.fit(z_train.toarray(), y_train_one_hot, \n","        validation_split=hyperM.val_split,\n","        epochs=hyperM.epochs, \n","        shuffle=True,\n","        verbose=0)\n","    else:\n","      early_stopping_callback = EarlyStopping(monitor='loss', patience=5, verbose=0)\n","      checkpoint_callback = ModelCheckpoint('GNN.h5', monitor='loss', save_best_only=True, mode='min', verbose=0)\n","      \n","      train_strat = time.time()\n","      history = model.fit(batch_generator(z_train, y_train, k, 32, True),\n","                      epochs=hyperM.epochs,\n","                      steps_per_epoch=z_train.shape[0],\n","                      callbacks=[early_stopping_callback, checkpoint_callback],\n","                      verbose=0)\n","    train_end = time.time()\n","    train_time = train_end - train_strat \n","\n","    y_test_one_hot = to_categorical(y_test, num_classes=k) \n","    # set verbose to 0 to silent the output\n","    test_loss, test_acc = gnn.model.evaluate(z_test.toarray(),  y_test_one_hot, verbose=0) \n","    return test_acc, train_time\n","############------------Sparse_supervised_learning_end---------###############\n"]},{"cell_type":"markdown","metadata":{"id":"G-kF5bByQt4t"},"source":["#Packages for Drive Files"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"BjvPSUD9Qt4u","executionInfo":{"status":"ok","timestamp":1667446107654,"user_tz":240,"elapsed":7,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["# import packages\n","## for mount drive purpose\n","import os\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"0quiQZnHBMnE"},"source":["#Mount Drive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24333,"status":"ok","timestamp":1667446131981,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"id":"2MytS4OrlCCg","outputId":"ca2fe81a-e73f-4ab2-f2f3-e4e742b79760"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["# mount drive\n","drive.mount('/content/drive/', force_remount=True)\n","os.chdir('/content/drive/My Drive/Colab_Notebooks/Graph_ML/semi_dr.shen')"]},{"cell_type":"markdown","metadata":{"id":"4oIeHWJ519n_"},"source":["# import ipynb packages"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7193,"status":"ok","timestamp":1667446139147,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"id":"1Z6GEpC02FnX","outputId":"1e2a385a-6f1c-4729-f725-8645f210dd32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import-ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.7.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (7.9.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.0.10)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.11.2)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.16.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (3.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.1\n"]}],"source":["!pip install import-ipynb"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4437,"status":"ok","timestamp":1667446143578,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"id":"6jrl3lFk0gZM","outputId":"54f2122e-0778-46ba-ae3b-fb9da386b46a"},"outputs":[{"output_type":"stream","name":"stdout","text":["importing Jupyter notebook from test_cases.ipynb\n","Mounted at /content/drive/\n"]}],"source":["import import_ipynb\n","from test_cases import Model, Case"]},{"cell_type":"code","source":["import import_ipynb\n","from test_cases_numba import Model, Case"],"metadata":{"id":"10_KZSd_8D2t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667442384157,"user_tz":240,"elapsed":1141,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"5f6a7513-c6f3-42f8-93ec-dd40d359761d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["importing Jupyter notebook from test_cases_numba.ipynb\n"]}]},{"cell_type":"markdown","metadata":{"id":"RRMhWS392g7w"},"source":["# Test Cases "]},{"cell_type":"markdown","source":["### Case_original vs case_numba"],"metadata":{"id":"V49yuvuWi3az"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"oHwAaAzhjJ_Q","executionInfo":{"status":"ok","timestamp":1667446143579,"user_tz":240,"elapsed":11,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["n = 5000\n","case = Case(n)"]},{"cell_type":"markdown","source":["#### Original-case"],"metadata":{"id":"X_PEnk0zjJ_R"}},{"cell_type":"markdown","source":["##### first-run \n","Disconnect and delete runtime first,\n","And then run the code for Numba only."],"metadata":{"id":"tbY0qOVMATAb"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyFbxH63AcEy","executionInfo":{"status":"ok","timestamp":1667445816789,"user_tz":240,"elapsed":46748,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"0e711a1c-8a75-4292-fe67-058504ef72bf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["46.59250783920288\n"]}]},{"cell_type":"markdown","source":["##### Second-run after run with original code\n","Run right after the first run"],"metadata":{"id":"wZ-m0H53AZHh"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPSEJINaAWqK","executionInfo":{"status":"ok","timestamp":1667445867794,"user_tz":240,"elapsed":43668,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"8ff1d179-cb31-4077-80d9-8f8cff48e919"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["43.531267166137695\n"]}]},{"cell_type":"markdown","source":["##### Another first-run \n","Disconnect and delete runtime first,\n","And then run the code for Numba only."],"metadata":{"id":"opfi76w1Af-q"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667446213414,"user_tz":240,"elapsed":69844,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"4fea8b9c-f615-4b46-b615-c8b4906a7e22","id":"Vh8vKTjKjJ_R"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["69.7140474319458\n"]}]},{"cell_type":"markdown","source":["#### Numba-case"],"metadata":{"id":"KQtgJsuwjJ_S"}},{"cell_type":"markdown","source":["##### first-run \n","Disconnect and delete runtime first,\n","And then run the code for Numba only."],"metadata":{"id":"nJF2FQzb-7_c"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667442451696,"user_tz":240,"elapsed":64471,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"7bb95826-d330-4218-d040-f95af21b2543","id":"CQpJAwfBjJ_S"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["64.10027313232422\n"]}]},{"cell_type":"markdown","source":["##### Second-run after run with numba code\n","Run right after the first run"],"metadata":{"id":"PO_NcsnU_PZ4"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tg-Lqy5X-WnF","executionInfo":{"status":"ok","timestamp":1667442290016,"user_tz":240,"elapsed":43701,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"b5a6baf3-e018-4af9-a436-af5933b1026a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["58.155558347702026\n"]}]},{"cell_type":"markdown","source":["##### Another first-run \n","Disconnect and delete runtime first,\n","And then run the code for Numba only."],"metadata":{"id":"W9o9UfeP_ZSd"}},{"cell_type":"code","source":["start = time.time()\n","case_test = case.case_10_fully_known()\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vunWuk65-paf","executionInfo":{"status":"ok","timestamp":1667442145009,"user_tz":240,"elapsed":65913,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"82ed7686-94e2-4d1d-ab4f-3931c2e81995"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["65.97182035446167\n"]}]},{"cell_type":"markdown","metadata":{"id":"7oU46iflSDT-"},"source":["###GEE_Sparse_Original vs GEE_sparse_Numba"]},{"cell_type":"markdown","metadata":{"id":"ur9t5Xj3FWJ5"},"source":["#### Case 10 with 3000 nodes (SBM)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"BKkH7rdnuD-A","executionInfo":{"status":"ok","timestamp":1667439249867,"user_tz":240,"elapsed":5,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["n = 3000\n","case = Case(n)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30451,"status":"ok","timestamp":1667439280314,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"id":"4lVkPbp1uHNK","outputId":"0a437663-6a18-4fee-a32a-6dabd44508f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Info:\n","\n","    SBM with 3 classes and defined probabilities with fully known labels\n","    80% for training and 20% for testing\n","    \n","n:\n","<class 'int'>\n","3000\n","d:\n","<class 'int'>\n","3\n","X:\n","(3000, 3000)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 1 0]]\n","Y:\n","(3000, 1)\n","[[1]\n"," [0]\n"," [2]\n"," ...\n"," [2]\n"," [2]\n"," [2]]\n"]}],"source":["case_10 = case.case_10_fully_known()\n","case_10.summary()"]},{"cell_type":"markdown","metadata":{"id":"gEB2KhBIIbD9"},"source":["#### Laplacian = True, DiagA = False, Correlation = False -- original"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1667438342529,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"outputId":"d746697b-7039-4e81-bdaf-4812b791b03e","id":"EoMMNM6UIbD9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.11637496948242188 seconds ---\n"]}],"source":["X_sparse = sparse.csr_matrix(case_10.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_10.Y, case_10.n, Laplacian = True, DiagA = False, Correlation = False)\n","print(\"--- embed %s seconds ---\" % emb_time)"]},{"cell_type":"markdown","metadata":{"id":"IQQ4cDfkh1xu"},"source":["#### Laplacian = True, DiagA = False, Correlation = False (nk/n) -- Numba"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1667439155268,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"outputId":"48a3866a-43e5-4920-d422-ddab1fd321bb","id":"wDZiX0pVh1xu"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.08033180236816406 seconds ---\n"]}],"source":["X_sparse = sparse.csr_matrix(case_10.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_10.Y, case_10.n, Laplacian = True, DiagA = False, Correlation = False)\n","print(\"--- embed %s seconds ---\" % emb_time)"]},{"cell_type":"markdown","source":["#### Laplacian = True, DiagA = True, Correlation = True -- original"],"metadata":{"id":"NIWszloZoPz8"}},{"cell_type":"code","source":["X_sparse = sparse.csr_matrix(case_10.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_10.Y, case_10.n, Laplacian = True, DiagA = True, Correlation = True)\n","print(\"--- embed %s seconds ---\" % emb_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOKr50DmoLip","executionInfo":{"status":"ok","timestamp":1667438517990,"user_tz":240,"elapsed":419,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"d1e2f065-babc-44f6-ce4a-c7f3d976aee9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.14231061935424805 seconds ---\n"]}]},{"cell_type":"markdown","source":["#### Laplacian = True, DiagA = True, Correlation = True -- Numba"],"metadata":{"id":"CZViA2tMojM2"}},{"cell_type":"code","source":["X_sparse = sparse.csr_matrix(case_10.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_10.Y, case_10.n, Laplacian = True, DiagA = True, Correlation = True)\n","print(\"--- embed %s seconds ---\" % emb_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWX1OXW4onPa","executionInfo":{"status":"ok","timestamp":1667439280610,"user_tz":240,"elapsed":320,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"0e34da5c-5fc3-41f7-8d4e-024d0e0b3e44"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.10345172882080078 seconds ---\n"]}]},{"cell_type":"markdown","metadata":{"id":"rtRTsYmHLRKR"},"source":["### Case 10 with 5000 nodes (SBM)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"9Ig_jPQULRKS","executionInfo":{"status":"ok","timestamp":1667446545164,"user_tz":240,"elapsed":423,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}}},"outputs":[],"source":["n = 5000\n","case = Case(n)"]},{"cell_type":"code","source":["case_test = case.case_10_fully_known()\n","case_test.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EGINiJzF2UA","executionInfo":{"status":"ok","timestamp":1667446615943,"user_tz":240,"elapsed":68813,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"f4eea49f-a0c8-4b03-f322-02b1db54c0d1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Info:\n","\n","    SBM with 3 classes and defined probabilities with fully known labels\n","    80% for training and 20% for testing\n","    \n","n:\n","<class 'int'>\n","5000\n","d:\n","<class 'int'>\n","3\n","X:\n","(5000, 5000)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]]\n","Y:\n","(5000, 1)\n","[[1]\n"," [0]\n"," [2]\n"," ...\n"," [2]\n"," [0]\n"," [1]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"jYEcIL5RLRKT"},"source":["#### Laplacian = True, DiagA = True, Correlation = True -- original"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1667446634000,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"},"user_tz":240},"id":"7Gi3zDHcLRKT","outputId":"16889266-8f83-4797-d692-b255d54f3b16"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.19189238548278809 seconds ---\n"]}],"source":["X_sparse = sparse.csr_matrix(case_test.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_test.Y, case_test.n, Laplacian = True, DiagA = True, Correlation = True)\n","print(\"--- embed %s seconds ---\" % emb_time)"]},{"cell_type":"markdown","source":["#### Laplacian = True, DiagA = True, Correlation = True -- Numba"],"metadata":{"id":"0EOaPFJjF9X2"}},{"cell_type":"code","source":["X_sparse = sparse.csr_matrix(case_test.X)\n","GEE = GraphEncoderEmbed()\n","Z, W, emb_time = GEE.run(X_sparse, case_test.Y, case_test.n, Laplacian = True, DiagA = True, Correlation = True)\n","print(\"--- embed %s seconds ---\" % emb_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_jKbpk0F7d8","executionInfo":{"status":"ok","timestamp":1667446659369,"user_tz":240,"elapsed":1315,"user":{"displayName":"Xihan Qin","userId":"10869877831647632037"}},"outputId":"ddc93ce1-5939-4c5e-877b-19f337253820"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["--- embed 0.22345662117004395 seconds ---\n"]}]}],"metadata":{"colab":{"collapsed_sections":["rdtkqKg_nhmj","4N9L480srX8a","nJF2FQzb-7_c","PO_NcsnU_PZ4","W9o9UfeP_ZSd","ur9t5Xj3FWJ5","gEB2KhBIIbD9","IQQ4cDfkh1xu","NIWszloZoPz8","CZViA2tMojM2","rtRTsYmHLRKR","jYEcIL5RLRKT","0EOaPFJjF9X2"],"provenance":[{"file_id":"1jTGoYc4dm3aOJYsUqNNlUV9L2DNs0lxM","timestamp":1661143614947}],"authorship_tag":"ABX9TyP+ZuVxbdmQXRteliz2XouP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}