{"cells":[{"cell_type":"markdown","metadata":{"id":"YdFl3x2SBBFf"},"source":["#Package Section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1feGDRiBv-2-"},"outputs":[],"source":["import sys\n","import numpy as np\n","import copy\n","from numpy import linalg as LA\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics.cluster import adjusted_rand_score\n","from sklearn.cluster import KMeans\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn import metrics\n","import time\n","# for sparse matrix\n","from scipy import sparse\n","#early stop\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ModelCheckpoint\n"]},{"cell_type":"markdown","metadata":{"id":"4N9L480srX8a"},"source":["#Classes and functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpkZjKLAskam"},"outputs":[],"source":["# invalide devide resutls will be nan\n","np.seterr(divide='ignore', invalid='ignore')\n","\n","############------------graph_encoder_embed_start----------------###############\n","class GraphEncoderEmbed:\n","  def run(self, X, Y, n, **kwargs):\n","    defaultKwargs = {'EdgeList': False, 'DiagA': True, 'Laplacian': False, 'Correlation': True}\n","    kwargs = { **defaultKwargs, **kwargs}\n","\n","    if kwargs['EdgeList']:\n","      size_flag = self.edge_list_size\n","      X = self.Edge_to_Sparse(X, n, size_flag)\n","    \n","    emb_strat = time.time()\n","\n","    if kwargs['DiagA']:\n","      X = self.Diagonal(X, n)\n","\n","    if kwargs['Laplacian']:\n","      X = self.Laplacian(X, n)\n","    \n","    Z, W = self.Basic(X, Y, n)\n","\n","    if kwargs['Correlation']:\n","      Z = self.Correlation(Z)\n","    \n","    emb_end = time.time()\n","    emb_time = emb_end - emb_strat\n","    \n","    return Z, W, emb_time\n","\n","  def Basic(self, X, Y, n):\n","    \"\"\"\n","      graph embedding basic function\n","      input X is sparse csr matrix of adjacency matrix\n","      -- if there is a connection between node i and node j:\n","      ---- X(i,j) = 1, no edge weight\n","      ---- X(i,j) = edge weight.\n","      -- if there is no connection between node i and node j:\n","      ---- X(i,j) = 0, \n","      ---- note there is no storage for this in sparse matrix. \n","      ---- No storage means 0 in sparse matrix.\n","      input Y is numpy array with size (n,1):\n","      -- value -1 indicate no lable\n","      -- value >=0 indicate real label\n","      input train_idx: a list of indices of input X for training set \n","    \"\"\"\n","    # assign k to the max along the first column\n","    # Note for python, label Y starts from 0. Python index starts from 0. thus size k should be max + 1\n","    k = Y[:,0].max() + 1\n","    \n","    #nk: 1*n array, contains the number of observations in each class\n","    nk = np.zeros((1,k))\n","    for i in range(k):\n","      nk[0,i] = np.count_nonzero(Y[:,0]==i)\n","    \n","    #W: sparse matrix for encoder matrix. W[i,k] = {1/nk if Yi==k, otherwise 0}\n","    W = sparse.dok_matrix((n, k), dtype=np.float32)\n","\n","    for i in range(n):\n","      k_i = Y[i,0]\n","      if k_i >=0:\n","        W[i,k_i] = 1/nk[0,k_i]\n","    \n","    W = sparse.csr_matrix(W)\n","    Z = X.dot(W)\n","\n","    return Z, W\n","\n","  def Diagonal(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of X matrix with 1s on the diagonal\n","    \"\"\"\n","    I = sparse.identity(n)\n","    X = X + I\n","    return X\n","\n","\n","  def Laplacian(self, X, n):\n","    \"\"\"\n","      input X is sparse csr matrix of adjacency matrix\n","      return a sparse csr matrix of Laplacian normalization of X matrix\n","    \"\"\"\n","    X_sparse = sparse.csr_matrix(X)\n","    # get an array of degrees\n","    dig = X_sparse.sum(axis=0).A1\n","    # diagonal sparse matrix of D\n","    D = sparse.diags(dig,0)\n","    _D = D.power(-0.5)\n","    # D^-0.5 x A x D^-0.5\n","    L = _D.dot(X_sparse.dot(_D)) \n","\n","    # _L = _D.dot(X_sparse.dot(_D))    \n","    # # L = I - D^-0.5 x A x D^-0.5\n","    # I = sparse.identity(n)\n","    # L = I - _L   \n","\n","    return L\n","  \n","  def Correlation(self, Z):\n","    \"\"\"\n","      input Z is sparse csr matrix of embedding matrix from the basic function\n","      return normalized Z sparse matrix\n","      Calculation:\n","      Calculate each row's 2-norm (Euclidean distance). \n","      e.g.row_x: [ele_i,ele_j,ele_k]. norm2 = sqr(sum(ele_i^2+ele_i^2+ele_i^2))\n","      then divide each element by their row norm\n","      e.g. [ele_i/norm2,ele_j/norm2,ele_k/norm2] \n","    \"\"\"\n","    # 2-norm\n","    row_norm = sparse.linalg.norm(Z, axis = 1)\n","\n","    # row division to get the normalized Z\n","    diag = np.nan_to_num(1/row_norm)\n","    N = sparse.diags(diag,0)\n","    Z = N.dot(Z)\n","\n","    return Z\n","\n","  def edge_list_size(self, X):\n","    \"\"\"\n","      set default edge list size as S3.\n","      If find X only has 2 columns, \n","      return a flag \"S2\" indicating this is S2 edge list\n","    \"\"\"\n","    if X.shape[1] == 2:\n","      return \"S2\"\n","    else:\n","      return \"S3\"\n","    \n","  def Edge_to_Sparse(self, X, n, size_flag):\n","    \"\"\"\n","      input X is an edge list.\n","      Note for X, the edge list: \n","      it is assumed there is no duplication of one connection\n","      e.g. connection between node i and node j, \n","      there is only one row for this connection. \n","      either (node_i, node_j, edge_w), or(node_j, node_i, edge_w)\n","      Only one of them. \n","      If there are duplication in your edge list, please remove them before run.\n","\n","      For S2 edge list (e.g. node_i, node_j per row), add one to all connections\n","      return a sparse csr matrix of S3 edge list\n","    \"\"\"   \n","    #Build an empty sparse matrix. \n","    X_new = sparse.dok_matrix((n, n), dtype=np.float32)\n","\n","    for row in X:\n","      if size_flag == \"S2\":\n","        [node_i, node_j] = row\n","        X_new[node_i, node_j] = 1\n","        X_new[node_j, node_i] = 1\n","      else:\n","        [node_i, node_j, weight] = row\n","        X_new[node_i, node_j] = weight\n","        X_new[node_j, node_i] = weight\n","    \n","    X_new = sparse.csr_matrix(X_new)\n","\n","    return X_new\n","\n","\n","############------------graph_encoder_embed_end------------------###############\n","############------------Sparse_supervised_learning_start---------###############\n","\n","# https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/22567\n","# https://github.com/tkipf/pygcn/blob/1600b5b748b3976413d1e307540ccc62605b4d6d/pygcn/utils.py#L73\n","\n","def batch_generator(X, y, k, batch_size, shuffle):\n","    number_of_batches = int(X.shape[0]/batch_size)\n","    counter = 0\n","    sample_index = np.arange(X.shape[0])\n","    if shuffle:\n","        np.random.shuffle(sample_index)\n","    while True:\n","        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n","        X_batch = X[batch_index,:].toarray()\n","        y_batch = to_categorical(y[batch_index], num_classes=k)\n","        counter += 1\n","        yield X_batch, y_batch\n","        if (counter == number_of_batches):\n","            if shuffle:\n","                np.random.shuffle(sample_index)\n","            counter = 0\n","\n","class Hyperperameters:\n","  \"\"\"\n","    define perameters for GNN.\n","    default values are for GNN learning -- \"Leaner\" ==2:\n","      embedding via partial label, then learn unknown label via two-layer NN\n","\n","  \"\"\"\n","  def __init__(self):\n","    # there is no scaled conjugate gradiant in keras optimiser, use defualt instead\n","    # use whatever default\n","    self.learning_rate = 0.01  # Initial learning rate.\n","    self.epochs = 100 #Number of epochs to train.\n","    self.hidden = 20 #Number of units in hidden layer \n","    self.val_split = 0.1 #Split 10% of training data for validation\n","    self.loss = 'categorical_crossentropy' # loss function\n","\n","class GNN:\n","  def __init__(self, DataSets):\n","    GNN.DataSets = DataSets\n","    GNN.hyperM = Hyperperameters()\n","    GNN.model = self.GNN_model()  #model summary: GNN.model.summary()\n","      \n"," \n","  def GNN_model(self):\n","    \"\"\"\n","      build GNN model\n","    \"\"\"\n","    hyperM = self.hyperM\n","    DataSets = self.DataSets\n","\n","    z_train = DataSets.z_train\n","    k = DataSets.d\n","\n","    feature_num = z_train.shape[1]\n","    \n","    model = keras.Sequential([\n","    keras.layers.Flatten(input_shape = (feature_num,)),  # input layer \n","    keras.layers.Dense(hyperM.hidden, activation='relu'),  # hidden layer -- no tansig activation function in Keras, use relu instead\n","    keras.layers.Dense(k, activation='softmax') # output layer, matlab used softmax for patternnet default ??? max(opts.neuron,K)? opts \n","    ])\n","\n","    optimizer = keras.optimizers.Adam(learning_rate = hyperM.learning_rate)\n","\n","    model.compile(optimizer='adam',\n","                  loss=hyperM.loss,\n","                  metrics=['accuracy'])\n","\n","    return model\n","    \n","  def GNN_run(self, flag):\n","    \"\"\"\n","      Train and test directly.\n","      Do not learn from the unknown labels.\n","    \"\"\"\n","    gnn = copy.deepcopy(self)\n","    hyperM = gnn.hyperM\n","    DataSets = self.DataSets\n","    k = DataSets.d\n","    z_train = DataSets.z_train\n","    y_train = DataSets.y_train\n","    y_test = DataSets.y_test\n","    z_test = DataSets.z_test\n","    model = gnn.model    \n","\n","\n","    if flag == \"direct\":\n","      y_train_one_hot = to_categorical(y_train, num_classes=k)\n","      train_strat = time.time() \n","      history = model.fit(z_train.toarray(), y_train_one_hot, \n","        validation_split=hyperM.val_split,\n","        epochs=hyperM.epochs, \n","        shuffle=True,\n","        verbose=0)\n","    else:\n","      early_stopping_callback = EarlyStopping(monitor='loss', patience=5, verbose=0)\n","      checkpoint_callback = ModelCheckpoint('GNN.h5', monitor='loss', save_best_only=True, mode='min', verbose=0)\n","      \n","      train_strat = time.time()\n","      history = model.fit(batch_generator(z_train, y_train, k, 32, True),\n","                      epochs=hyperM.epochs,\n","                      steps_per_epoch=z_train.shape[0],\n","                      callbacks=[early_stopping_callback, checkpoint_callback],\n","                      verbose=0)\n","    train_end = time.time()\n","    train_time = train_end - train_strat \n","\n","    y_test_one_hot = to_categorical(y_test, num_classes=k) \n","    # set verbose to 0 to silent the output\n","    test_loss, test_acc = gnn.model.evaluate(z_test.toarray(),  y_test_one_hot, verbose=0) \n","    return test_acc, train_time\n","############------------Sparse_supervised_learning_end---------###############\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"GraphEncoder_Sparse.ipynb","provenance":[{"file_id":"1jTGoYc4dm3aOJYsUqNNlUV9L2DNs0lxM","timestamp":1661143614947}],"authorship_tag":"ABX9TyNnLZCJUlnB5mrRvhkoavqM"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}